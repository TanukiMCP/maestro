# TanukiMCP Maestro Test Suite

Comprehensive testing suite for the production-ready MCP server that validates both Smithery.ai compatibility and real-world agentic IDE functionality.

## ðŸŽ¯ What This Test Suite Validates

### âœ… Smithery.ai Compatibility
- **Instant Tool Discovery**: All tools register in <100ms for Smithery scanning
- **Static Tool Schemas**: No dynamic imports or side effects during tool listing
- **FastMCP Integration**: Proper MCP protocol compliance

### âœ… Real-World Functionality  
- **Natural Language Processing**: Tools work with natural language requests from agentic IDEs
- **Complex Workflows**: Multi-step orchestration and tool integration
- **Error Handling**: Graceful handling of edge cases and invalid inputs
- **Production Scenarios**: Code review, architecture guidance, debugging assistance

## ðŸ“ Test Structure

```
tests/
â”œâ”€â”€ __init__.py                 # Test suite initialization
â”œâ”€â”€ test_tool_orchestrate.py    # Core orchestration functionality
â”œâ”€â”€ test_tool_search.py         # Enhanced web search capabilities  
â”œâ”€â”€ test_tool_iae.py           # Intelligence Amplification Engine
â”œâ”€â”€ test_remaining_tools.py     # All other tools (collaboration, execution, etc.)
â”œâ”€â”€ test_all_tools.py          # Integration testing and comprehensive workflows
â”œâ”€â”€ run_all_tests.py           # Main test runner with detailed reporting
â””â”€â”€ README.md                  # This documentation
```

## ðŸš€ Running Tests

### Quick Test (Individual Tools)
```bash
# Test individual tool
cd tests
python test_tool_orchestrate.py

# Test search functionality
python test_tool_search.py

# Test IAE capabilities
python test_tool_iae.py
```

### Comprehensive Test Suite
```bash
# Run all tests with detailed reporting
cd tests
python run_all_tests.py
```

### Using pytest (Optional)
```bash
# Install pytest if not available
pip install pytest pytest-asyncio

# Run with pytest
cd tests
pytest -v
```

## ðŸ“Š Test Categories

### 1. **Tool Registration Tests**
Validates that all 11 tools are properly registered:
- `maestro_orchestrate` - Core task orchestration
- `maestro_iae` - Intelligence Amplification Engine
- `get_available_engines` - Engine discovery
- `maestro_iae_discovery` - Agent discovery
- `maestro_tool_selection` - Intelligent tool routing
- `maestro_collaboration_response` - Multi-agent coordination
- `maestro_search` - Enhanced web search
- `maestro_scrape` - Web content extraction
- `maestro_execute` - Code/command execution
- `maestro_temporal_context` - Time-aware analysis
- `maestro_error_handler` - Error analysis and recovery

### 2. **Functional Tests**
Real-world scenarios that an agentic IDE would encounter:
- **Code Review**: "Help me review this Python function for issues"
- **Architecture Guidance**: "What database should I use for 1M users?"
- **Learning Assistance**: "Explain how OAuth 2.0 works"
- **Performance Analysis**: "Compare async/await vs callbacks in JavaScript"

### 3. **Integration Tests**
Complex workflows using multiple tools:
- Task orchestration â†’ Engine discovery â†’ Specialized analysis â†’ Web research â†’ Tool selection
- End-to-end validation of the full tool ecosystem

### 4. **Error Handling Tests**
Edge cases and boundary conditions:
- Empty inputs
- Invalid parameters  
- Network failures
- Graceful degradation

## ðŸŽ›ï¸ Test Configuration

### Environment Variables
```bash
# Optional: Enable debug mode for detailed logging
export DEBUG_MODE=true

# Optional: Set test timeout
export TEST_TIMEOUT=30
```

### Test Customization
Modify test parameters in individual test files:
```python
# Adjust complexity levels
complexity_levels = ["minimal", "moderate", "high", "maximum"]

# Modify search parameters
max_results = 10
temporal_filter = "recent"

# Customize orchestration settings
quality_threshold = 0.8
enable_collaboration = True
```

## ðŸ“ˆ Production Readiness Criteria

Tests validate these production requirements:

### âœ… Performance
- Tool registration: <100ms (Smithery requirement)
- Response times: <30s for complex tasks
- Memory usage: Efficient lazy loading

### âœ… Reliability  
- 100% success rate on basic functionality
- Graceful error handling for all edge cases
- No crashes on invalid inputs

### âœ… Compatibility
- FastMCP protocol compliance
- Smithery.ai instant discovery
- Agentic IDE natural language support

### âœ… Functionality
- All 11 tools operational
- Real-world scenario handling
- Multi-tool integration workflows

## ðŸ› Troubleshooting

### Common Issues

**ImportError: No module named 'server'**
```bash
# Ensure you're in the correct directory
cd tests
python test_all_tools.py
```

**Tool registration failures**
```bash
# Check server can be imported
python -c "import server; print('Server OK')"
```

**Async/await errors**
```bash
# Ensure Python 3.7+ is being used
python --version
```

### Debug Mode
Enable detailed logging:
```bash
export DEBUG_MODE=true
python run_all_tests.py
```

## ðŸ“‹ Test Report Example

```
============================================================
  TanukiMCP Maestro - Production Readiness Test Suite
============================================================
ðŸš€ Starting comprehensive testing at 2025-01-04 15:30:45

ðŸ“‹ Quick Import Validation
----------------------------------------
âœ… Server module imports successfully
âœ… FastMCP instance available  
âœ… 11 tools registered

ðŸ“‹ Running test_tool_orchestrate
----------------------------------------
âœ… maestro_orchestrate properly registered for Smithery scanning
âœ… Simple orchestration completed: 1247 characters
âœ… Complex orchestration completed: 2156 characters
âœ… test_tool_orchestrate completed successfully in 3.45s

...

============================================================
  TEST EXECUTION SUMMARY
============================================================
ðŸ“Š Total Tests Run: 5
âœ… Successful: 5
âŒ Failed: 0
â±ï¸  Total Duration: 15.67 seconds

============================================================
  PRODUCTION READINESS ASSESSMENT
============================================================
ðŸŽ‰ PRODUCTION READY!

âœ… All tools properly registered for Smithery.ai scanning
âœ… All tools functional with real-world scenarios
âœ… Integration workflows working correctly
âœ… Error handling working properly
âœ… Natural language processing functional

ðŸš€ TanukiMCP Maestro is ready for deployment!

ðŸ“‹ Production Metrics
----------------------------------------
ðŸ“ˆ Tool Registration Time: <100ms (Smithery compatible)
ðŸ“ˆ Average Response Time: 3.13s
ðŸ“ˆ Success Rate: 100.0%
ðŸ“ˆ Error Recovery: Graceful handling verified
```

## ðŸ”— Related Documentation

- [Server Implementation](../server.py)
- [MaestroTools](../src/maestro_tools.py)
- [Smithery Configuration](../smithery.yaml)
- [Production Validation](../validate_production.py)

## ðŸ¤ Contributing

When adding new tools or features:

1. **Add tool registration test** in `test_all_tools.py`
2. **Create functional tests** with real-world scenarios
3. **Add integration test cases** if the tool interacts with others
4. **Update this README** with new test descriptions
5. **Run full test suite** to ensure compatibility

## ðŸ“„ License

Tests are covered under the same license as the main TanukiMCP Maestro project. 